{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Traffic sign classifier\n",
    "Documentation and implementation by Kevin Hubert.\n",
    "\n",
    "## Intro\n",
    "This project is my implementation of the traffic-sign-classifier project during the \n",
    "Nanodegree program \"Self-Driving car engineer\" at Udacity.com.\n",
    "\n",
    "The project contains the following part to fulfill all requirments:\n",
    "* Load/Visualize provided data set\n",
    "* Generate additional data for types with least data\n",
    "* Visualize the distribution after data-generation\n",
    "* Normalize the given and generated data\n",
    "* Design and train a CNN-model architecture\n",
    "* Evaluate the trained model with validation-/test-data\n",
    "* Make predictions with the trained model for additional images (new images)\n",
    "* Analyze the top-n predicted probabilities of the additional images\n",
    "* Create a writeup and visualize results\n",
    "\n",
    "\n",
    "## Load/Visualize provided data set\n",
    "A basic dataset of 43 different types of traffic sign images was provided. All of those image have a size of 32x32 pixels colored in RGB-colorspace. A basic overview of some images:\n",
    "![Examples of the traffic sign dataset](./figures/traffic_sign_dataset_example.png)\n",
    "\n",
    "As you can see in the image-list above, the lightning conditions and even the entire quality of the images are various.\n",
    "After creating a visualation about the distribution of the traffic-signs images, i was able to see the irregular amount of traffic signs images for each type:\n",
    "![Traffic sign types by type (histogram) without generated data](./figures/histogram_without_generated_data.png)\n",
    "\n",
    "Escpecially the types: 1, 18, 26, 28, 38 have comparably few images (~200)\n",
    "On the other hand other types have huge amount of provided images like 2, 3, 11, 12, 37 which have >1800.\n",
    "This can lead to different problems during the training and evaluation of the network, because the network will (may) more likely identify images as thoose types, which have relatively large amount of example.\n",
    "\n",
    "This problem is due to the fact that the types with particularly many data sets, which correspond to the same types, are learned more diversely.\n",
    "On the other hand, the types with relatively few examples are too rarely recognized because too few different representations are learned in addition to the known few example images.\n",
    "\n",
    "## Generate additional data\n",
    "As described in the previous chapter it is necessary to add additional data for those types, which has low amount of examples. To solve the problem it could be possible, to get more data, which will take a lot of time or otherwise use the exists image to generate more examples. I've decided to generate more data based on the given once to be able to complete the project in time.\n",
    "\n",
    "Therefor i've written a function, which takes in an image and rotates/zoom it as given in parameters.\n",
    "Because the rotation of a image creates black-pixels at the corners (there where not pixels are given) i'll crop x-pixels at the edges of the image and resize it to the required size of 32x32 pixel afterward. \n",
    "An visualize example can be seen here:\n",
    "![Visualization of new generated traffic sign images based on existing one](./figures/variation_generation_visualized.png)\n",
    "\n",
    "After finishing the function to create more variants of an image i've written a function to get the type with lowest amount of image and iterate through all of the given images to create additional images within the function described.\n",
    "In the end the list of new generated images is appended to the dataset. At the moment i do this 10times. This may could be done even more then 10 times but already lead to good results in my case. Moreover i recommend to not do this too often, because my function would also use the generated data from previous iteration which will lead to just more rotate/zoomed images.\n",
    "\n",
    "Within this functionality i've increased the amount of datasets from 35339 to 41189 images.\n",
    "This means i've added +5850 ~16.5% of generate images. \n",
    "\n",
    "The histogram with generated data:\n",
    "![Traffic sign types by type (histogram) with generated data](./figures/histogram_with_generated_data.png)\n",
    "\n",
    "\n",
    "## Image preparation/normalization\n",
    "\n",
    "In the first try i've just converted the images from RGB to grayscale, because this will reduce the amount of required neurons and so reduce the time to train the network. Moreover researched showed, that traffic-signs are more likely do be identified based on the given shapes instead of the colors. Last but not least due to the different lightning conditions, the saturation of the colors for the same type of traffic sign appears very variant.\n",
    "\n",
    "After converting all images to grayscale i've decided to normalize the value-range from 0-255 (grayscale) to -1.0 - +1.0  (input for a neural network should be in the range from -1.0 - +1.0) using the following formula:\n",
    "x = (x - 128) / 128\n",
    "\n",
    "Here are some examples how the values are before vs after.\n",
    "\n",
    "|Before|After      |\n",
    "|:----:|:---------:|\n",
    "|255   |0.9921875  |\n",
    "|192   |0.5        |\n",
    "|128   |0          |\n",
    "|64    |-0.5       |\n",
    "|0     |-1         |\n",
    "\n",
    "In the next step i've used the Histogram equalization to increase the contrast of the image by spreading the most frequent intensity values. A quite good description about the histogram equalization can be found here: https://towardsdatascience.com/histogram-equalization-5d1013626e64\n",
    "\n",
    "Here are some example using the normalization described above:\n",
    "![Traffic sign images normalized simple](./figures/simple_image_normalization.png)\n",
    "\n",
    "\n",
    "During more research about image preparation and normalization to improve the accurancy of my CNN i've discovered a stackoverflow post about the so called mean-substraction and standard-derivation-dividing.\n",
    "In the first step each pixel in the image is subtracted by the mean pixel value of the grayscaled image in the next step this value is now divided by the standard-derivation of the mean-subtracted-pixels of the images.\n",
    "\n",
    "\n",
    "In code i looks like this:\n",
    "\n",
    "```python\n",
    "def normalization_image_improved(rgb_image):\n",
    "    grayscaled = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "    mean_substracted = grayscaled - np.mean(grayscaled)\n",
    "    return (mean_substracted / np.std(mean_substracted)).reshape(32,32,1)\n",
    "```\n",
    "\n",
    "Stackoverflow-Thread: https://stackoverflow.com/questions/45301648/normalize-the-validation-set-for-a-neural-network-in-keras\n",
    "\n",
    "Using this normalization my accurancy of the network was improved by >5%.\n",
    "\n",
    "The result of the normalization function is shown below:\n",
    "> Keep in mind, that the mean subtraction and std-derivation-dividing does not affect the image-representation it converted they image-pixel-values (grayscaled 0-255) which will look equally when visualized using pyplot.\n",
    "\n",
    "![Traffic sign images normalized within std-derivation and meansubstract](./figures/advanced_image_normalization.png)\n",
    "\n",
    "\n",
    "\n",
    "## CNN Model architecture\n",
    "\n",
    "I've used the following hyper-parameters during my model-training:\n",
    "> EPOCHS = 25\n",
    ">\n",
    "> BATCH_SIZE = 64\n",
    ">\n",
    "> LEARN_RATE = 0.0006\n",
    "\n",
    "By using a higher learn-rate i was able to reduce the amount of epochs but also not reached a accurancy with a value +99% for the training-data.\n",
    "\n",
    "To train the model which is done by adjusting the weights/biases, i've choose the cross-entropy reduction using the stochastic gradient descent. For my sake the cross-entropy-calculation (based on the delta of the predicted vs correct result) is already part of the tensorflow library. As an optimizer i've used the AdamOptimizer which is a extension of the well known stochastic gradient descent which works especially good for deep-neural-networks.\n",
    "More about the AdamOptimizer can be found here: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "\n",
    "Using the hyperparameters shown above my model reaches the following accurancies (+/- 0.02)\n",
    "> Finished EPOCH 25/25 ...\n",
    ">\n",
    "> Validation Accuracy = 0.970\n",
    ">\n",
    "> Training Accuracy   = 0.996\n",
    "\n",
    "As you can see there is a delta of 2.6 (99.6 - 97.0) this may could be reduced by increase the dropouts of the CNN.\n",
    "On the other hand this may also reduces the training-accurancy. \n",
    "\n",
    "My model consisted of the following layers:\n",
    "\n",
    "|Step| Layer         \t\t|Description\t        \t\t\t\t\t              | \n",
    "|:--:|:--------------------:|:--------------------------------------------------------:| \n",
    "| 1  | Input         \t\t|32x32x1 Grayscaled/Normalized image\t\t\t           | \n",
    "| 2  | Convolution 5x5     \t|1x1 stride, valid padding, outputs 28x28x8 \t           |\n",
    "| 3  | RELU (activation) \t|\t\t\t\t\t\t\t\t\t\t\t               |\n",
    "| 4  | Max pooling\t      \t|2x2 stride, outputs 14x14x8  \t\t\t\t               |\n",
    "| 5  | Convolution 5x5     \t|1x1 stride, valid padding, outputs 10x10x24\t           |\n",
    "| 6  | RELU (activation) \t|\t\t\t\t\t\t\t\t\t\t\t               |\n",
    "| 7  | Max pooling\t      \t|2x2 stride, outputs 5x5x24   \t\t\t\t               |\n",
    "| 8  | Convolution 1x1     \t|1x1 stride, valid padding, outputs 5x5x16. Reduces depth  |\n",
    "| 9  | RELU (activation) \t|\t\t\t\t\t\t\t\t\t\t\t               |\n",
    "| 10 | Flatten    \t      \t|5x5x16 will be flatted to 400 \t\t    \t               |\n",
    "| 11 | Dropout              | Only for training (0.6 keep probablity)                  |\n",
    "| 12 | Full connected layer |In 400 Out 160\t\t\t\t\t\t\t\t               |\n",
    "| 13 | RELU\t\t            | \t\t\t\t\t\t\t\t\t                       |\n",
    "| 14 | Dropout\t\t\t\t|Only for training (0.6 keep probablity)                   |\n",
    "| 15 | Full connected layer |In 160 Out 129\t\t\t\t\t\t\t\t               |\n",
    "| 16 | RELU\t\t            | \t\t\t\t\t\t\t\t\t                       |\n",
    "| 17 | Full connected layer |In 129 Out 43  \t\t\t\t\t\t\t\t           |\n",
    "| 18 | Softmax              | Softmax                                                  |\n",
    "\n",
    "Next to the table-oriented representation i've created a visualization within the online platform Draw.io\n",
    "Please keep in mind, that the Diagram does not contains the activation-function and does also not contain the dropouts as described in the table above.\n",
    "![CNN layers visualized](./figures/CNN_Architecture.png)\n",
    "\n",
    "After each epoch i've evaluate the CNN within the training- and the validation-data. By comparing the values of accurancy it is more easy to see how well the model learns and even if the curves are close to each other or have a big delta (could be a sign for overfitting). While training my network i've viewed this values and added the 2 dropouts you can see in the model-architecture above to avoid overfitting.\n",
    "\n",
    "The curve of accurancy for both the training- and validation-data:\n",
    "![Learn rate for train and validation data](./figures/learning_rate.png)\n",
    "\n",
    "My final accurancy for the test-data-set was:\n",
    "test_accurancy >94.9%\n",
    "\n",
    "## Additional traffic sign images\n",
    "In the next step i've added 6 additional images of traffic signs from the internet.\n",
    "The image sources are the following:\n",
    "* Speed limit (30km/h) = https://media0.faz.net/ppmedia/aktuell/3322679104/1.6434912/mmobject-still_full/verkehrsberuhigt-tagsueber.jpg\n",
    "* Slippery road - https://c8.alamy.com/comp/CF48A4/a-rural-slippery-road-sign-with-a-snow-covered-road-in-the-background-CF48A4.jpg\n",
    "* Go straight or right - https://www.rhinocarhire.com/CorporateSite/media/Drive-Smart/Road-Signs/Mandatory-Signs/Germany-Mandatory-Sign-Driving-straight-ahead-or-turning-right-mandatory.png\n",
    "* Road work - https://media.istockphoto.com/photos/german-road-sign-for-construction-works-picture-id532189779?k=6&m=532189779&s=612x612&w=0&h=iWNSAFHYi1CNFtDkLpgWEDWWK06viBf9gTEl5yWB_bo=\n",
    "* Keep right - https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Keep_right_Portugal_20100107.jpg/170px-Keep_right_Portugal_20100107.jpg\n",
    "* Stop - http://www.ilankelman.org/stopsigns/germany.jpg\n",
    "\n",
    "In may case the name of the image represent the specific type. For sure this won't worked when adding mutliple images of the same type but this was not required in this case.\n",
    "The added images can be seen here:\n",
    "![Additional traffic signs](./figures/additional_traffic_signs.png)\n",
    "\n",
    "After importing the images i've normalized them the same way i've normalized the image for the CNN trained above\n",
    "When the normalization was done:\n",
    "![Additional traffic signs normalized](./figures/addition_traffic_signs_normalized.png)\n",
    "\n",
    "The accurancy for these image was 1.0 which means 100% were corrently identified.\n",
    "\n",
    "In the last step i've processed the images using the the tensorflow.nn.top_k function which allows me to visualize the top_n predicted outputs of the CNN for the specific image.\n",
    "\n",
    "This is especially interesting, because that way we can see which image was predicted with nearly 100% correctly or for which image the network was not absolutly sure. Moreover if the network missclassifies an image, it will visualize which types were predicted and how accurate.\n",
    "\n",
    "The prediction for my chosen image are shown below:\n",
    "\n",
    "![Top 5 prediction for additional traffic signs](./figures/top_n_prediction_for_additional_trafficsigns_barchart.png)\n",
    "\n",
    "\n",
    "## Possible improvments\n",
    "\n",
    "1.) For sure the image i've found on the internet for the \"Additional traffic sign images\"-chapter were quite simple to identify because they were front-faced-captured and have good lightning conditions. It could be interesting to make own traffic sign images and let the network predict the images. This could show if the CNN even works good when it dark/raining etc.\n",
    "\n",
    "2.) Additional training data may improve the CNN training even more. As you can see in the accurancy shown above the following values were reached:\n",
    "\n",
    "> Training: ~99.5%\n",
    ">\n",
    "> Validation: ~97.0%\n",
    ">\n",
    "> Test: ~94.9%\n",
    "\n",
    "I think this values can even be increase, when the training-dataset contains more image especially for those types were i've generated additional data. Because the generated data helps improving network for sure but more image within different lightning conditions may even increase the diversity.\n",
    "\n",
    "3.) Higher resolution. All provided images have a resolution of 32x32 pixels. Even my created network will only work within 32x32 images. I can imagine that a higher resolution may lead to better results. On the other hand a higher resolution would dramatically increase the required training-time and even the prediction would take more time.\n",
    "\n",
    "4.) Increase dropout to reduce the delta between the accurancy for the training-/validation-data as described before.\n",
    "\n",
    "5.) Combine multiple CNNs. May it could be clever to combine multiple networks to reduce the wrong-predictions. An example could be to create a network just for type-groups (e.g. Speed-Limit-Sign) and then use the already created network for the detailed prediction. Using a combination it may could indicate discrepancies when e.g. the first networks says type \"Stop\" and the detailed network says \"Speed limit 130\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
